{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Proccessing\n","metadata":{}},{"cell_type":"markdown","source":"<ul>\n  <p style=\"color:black; font-size:36px;\">Goals</p>\n  <li><p style=\"color:red; font-size:18px;\">We possess a dataset with details on sale prices.</p></li>\n  <li><p style=\"color:orange; font-size:18px;\">Our Goals is to create a model that forecasts sale prices for new data.</p></li>\n  <li><p style=\"color:purple; font-size:18px;\">This task involves examining the current data to uncover patterns and relationships that can guide our predictions.</p></li>\n  <li><p style=\"color:green; font-size:18px;\">By training our model on this dataset, we strive to improve its accuracy and dependability for future sales forecasts.</p></li>\n  <li><p style=\"color:blue; font-size:18px;\">Leveraging various features from the dataset, we intend to build a strong predictive tool to aid in making informed pricing decisions.</p></li>\n</ul>\n","metadata":{}},{"cell_type":"markdown","source":"## Import library","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\nimport seaborn as sns\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:13.913882Z","iopub.execute_input":"2024-08-05T13:17:13.914311Z","iopub.status.idle":"2024-08-05T13:17:30.954399Z","shell.execute_reply.started":"2024-08-05T13:17:13.914279Z","shell.execute_reply":"2024-08-05T13:17:30.953281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data set\n","metadata":{}},{"cell_type":"code","source":"train_file_path = \"../input/house-prices-advanced-regression-techniques/train.csv\"\ndataset = pd.read_csv(train_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:30.956300Z","iopub.execute_input":"2024-08-05T13:17:30.956945Z","iopub.status.idle":"2024-08-05T13:17:31.036093Z","shell.execute_reply.started":"2024-08-05T13:17:30.956885Z","shell.execute_reply":"2024-08-05T13:17:31.034473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check what's train data set look like ?","metadata":{}},{"cell_type":"code","source":"print(\"Train dataset shape is {}\".format(dataset.shape))\ndataset.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:31.037502Z","iopub.execute_input":"2024-08-05T13:17:31.037860Z","iopub.status.idle":"2024-08-05T13:17:31.080595Z","shell.execute_reply.started":"2024-08-05T13:17:31.037829Z","shell.execute_reply":"2024-08-05T13:17:31.079435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"remove column \"Id\" from the dataset","metadata":{}},{"cell_type":"code","source":"dataset = dataset.drop('Id', axis=1)\ndataset.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:31.083378Z","iopub.execute_input":"2024-08-05T13:17:31.083756Z","iopub.status.idle":"2024-08-05T13:17:31.110413Z","shell.execute_reply.started":"2024-08-05T13:17:31.083725Z","shell.execute_reply":"2024-08-05T13:17:31.109203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9, 8))  \nsns.histplot(dataset['SalePrice'].dropna(), color='purple', bins=100, alpha=0.4)  # Drop NaN values for plotting  \nplt.title('Distribution of Sale Prices')  \nplt.xlabel('Sale Price')  \nplt.ylabel('Frequency')  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:31.112160Z","iopub.execute_input":"2024-08-05T13:17:31.112558Z","iopub.status.idle":"2024-08-05T13:17:31.594271Z","shell.execute_reply.started":"2024-08-05T13:17:31.112525Z","shell.execute_reply":"2024-08-05T13:17:31.592972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:18px;\">*** &#9733;&#9733;&#9733;In the world of real estate, every home has a story to tell, and every house price narrates a unique tale of its own. Letâ€™s embark on a journey together to explore the distribution of house prices, uncovering how each price reflects the lives, dreams, and efforts of the people who call these houses their homes. &#9733;&#9733;&#9733; *** &#127769;</p>\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, HTML\nhtml = '<p style=\"color:red; font-size:18px;\">**Data description**</p>'\ndisplay(HTML(html))\nprint( dataset['SalePrice'].describe())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:36:57.051150Z","iopub.execute_input":"2024-08-05T13:36:57.052252Z","iopub.status.idle":"2024-08-05T13:36:57.064607Z","shell.execute_reply.started":"2024-08-05T13:36:57.052211Z","shell.execute_reply":"2024-08-05T13:36:57.063223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:18px;\">Let's dive into exploring the distribution of our numerical features.\n    To do this, we'll start by listing all the data types in our dataset and then cherry-pick the numerical ones.  </P>","metadata":{}},{"cell_type":"markdown","source":"## Disturbution of our numical features\n","metadata":{}},{"cell_type":"code","source":"list(set(dataset.dtypes.tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:31.614175Z","iopub.execute_input":"2024-08-05T13:17:31.614627Z","iopub.status.idle":"2024-08-05T13:17:31.623295Z","shell.execute_reply.started":"2024-08-05T13:17:31.614586Z","shell.execute_reply":"2024-08-05T13:17:31.621981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_num = dataset.select_dtypes(include = ['float64', 'int64'])\ndf_num.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:31.624983Z","iopub.execute_input":"2024-08-05T13:17:31.625351Z","iopub.status.idle":"2024-08-05T13:17:31.648712Z","shell.execute_reply.started":"2024-08-05T13:17:31.625311Z","shell.execute_reply":"2024-08-05T13:17:31.647433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Plot the Heat map to see correlation between each variables","metadata":{}},{"cell_type":"code","source":"\nnumeric_dataset = dataset.select_dtypes(include=[np.number])  # Select only numeric columns\ncorrmat = numeric_dataset.corr()  # Compute the correlation matrix\n\nk = 10  # Number of variables for the heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index  # Get the top 'k' correlations with 'SalePrice'\ncm = np.corrcoef(numeric_dataset[cols].values.T)  # Compute the correlation coefficients for the selected columns\n\nsns.set(font_scale=1.25)\nplt.figure(figsize=(10, 8))\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10},\n                 yticklabels=cols.values, xticklabels=cols.values)\nplt.title('Correlation Matrix Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:31.650122Z","iopub.execute_input":"2024-08-05T13:17:31.650490Z","iopub.status.idle":"2024-08-05T13:17:32.387880Z","shell.execute_reply.started":"2024-08-05T13:17:31.650456Z","shell.execute_reply":"2024-08-05T13:17:32.386671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# So Let's plot the Histrogram to see relation between each variables and frequency","metadata":{}},{"cell_type":"code","source":"colors = ['orange', 'purple', 'gray', 'red', 'blue']\ncolors = colors * ((len(df_num.columns) // len(colors)) + 1)  # Repeat colors\n\n# Number of subplots\nnum_features = len(df_num.columns)\nrows = (num_features + 1) // 2  # Calculate the number of rows for the layout\n\n# Create figure and subplots\nfig, axes = plt.subplots(nrows=rows, ncols=2, figsize=(16, rows * 5))\naxes = axes.flatten()  # Flatten the subplot array for easy access\n\n# Plot histograms with different colors\nfor i, (column, ax) in enumerate(zip(df_num.columns, axes)):\n    df_num[column].hist(ax=ax, bins=50, color=colors[i], alpha=0.7)\n    ax.set_title(column)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n\n# Remove extra axes if the number of features is less than the number of subplots\nfor j in range(num_features, len(axes)):\n    fig.delaxes(axes[j])\n\n# Adjust layout\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:32.392558Z","iopub.execute_input":"2024-08-05T13:17:32.393421Z","iopub.status.idle":"2024-08-05T13:17:47.960217Z","shell.execute_reply.started":"2024-08-05T13:17:32.393377Z","shell.execute_reply":"2024-08-05T13:17:47.959096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets try some models","metadata":{}},{"cell_type":"markdown","source":" # 1.Random Forest","metadata":{}},{"cell_type":"code","source":"def split_datasett(datase, test_ratio=0.3):\n  test_indices = np.random.rand(len(datase)) < test_ratio\n  return datase[~test_indices], datase[test_indices]\n\ntrain_ds_pd, valid_ds_pd = split_datasett(dataset)\nprint(\"{} examples in training, {} examples in testing.\".format(\n    len(train_ds_pd), len(valid_ds_pd)))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:47.961696Z","iopub.execute_input":"2024-08-05T13:17:47.962130Z","iopub.status.idle":"2024-08-05T13:17:47.973248Z","shell.execute_reply.started":"2024-08-05T13:17:47.962093Z","shell.execute_reply":"2024-08-05T13:17:47.972018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = 'SalePrice'\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:47.974793Z","iopub.execute_input":"2024-08-05T13:17:47.975190Z","iopub.status.idle":"2024-08-05T13:17:48.605469Z","shell.execute_reply.started":"2024-08-05T13:17:47.975159Z","shell.execute_reply":"2024-08-05T13:17:48.604177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfdf.keras.get_all_models()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:48.607153Z","iopub.execute_input":"2024-08-05T13:17:48.607530Z","iopub.status.idle":"2024-08-05T13:17:48.614413Z","shell.execute_reply.started":"2024-08-05T13:17:48.607498Z","shell.execute_reply":"2024-08-05T13:17:48.613186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\nrf.compile(metrics=[\"mse\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:48.616031Z","iopub.execute_input":"2024-08-05T13:17:48.617402Z","iopub.status.idle":"2024-08-05T13:17:48.691496Z","shell.execute_reply.started":"2024-08-05T13:17:48.617367Z","shell.execute_reply":"2024-08-05T13:17:48.689861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.fit(x=train_ds)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:17:48.693316Z","iopub.execute_input":"2024-08-05T13:17:48.693782Z","iopub.status.idle":"2024-08-05T13:18:04.070339Z","shell.execute_reply.started":"2024-08-05T13:17:48.693740Z","shell.execute_reply":"2024-08-05T13:18:04.068991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlogs = rf.make_inspector().training_logs()\nplt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"RMSE (out-of-bag)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:18:04.072288Z","iopub.execute_input":"2024-08-05T13:18:04.072692Z","iopub.status.idle":"2024-08-05T13:18:04.384795Z","shell.execute_reply.started":"2024-08-05T13:18:04.072659Z","shell.execute_reply":"2024-08-05T13:18:04.383670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's see how much a feature contributes to the model predictions","metadata":{}},{"cell_type":"code","source":"inspector = rf.make_inspector()\ninspector.evaluation()\nevaluation = rf.evaluate(x=valid_ds,return_dict=True)\n\nfor name, value in evaluation.items():\n  print(f\"{name}: {value:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:18:04.386185Z","iopub.execute_input":"2024-08-05T13:18:04.386537Z","iopub.status.idle":"2024-08-05T13:18:10.601960Z","shell.execute_reply.started":"2024-08-05T13:18:04.386508Z","shell.execute_reply":"2024-08-05T13:18:10.600872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Available variable importances:\")\nfor importance in inspector.variable_importances().keys():\n  print(\"\\t\", importance)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:18:10.603202Z","iopub.execute_input":"2024-08-05T13:18:10.603518Z","iopub.status.idle":"2024-08-05T13:18:10.612042Z","shell.execute_reply.started":"2024-08-05T13:18:10.603492Z","shell.execute_reply":"2024-08-05T13:18:10.610609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspector.variable_importances()[\"NUM_AS_ROOT\"]\nplt.figure(figsize=(12, 4))\n\n# Mean decrease in AUC of the class 1 vs the others.\nvariable_importance_metric = \"NUM_AS_ROOT\"\nvariable_importances = inspector.variable_importances()[variable_importance_metric]\n\n# Extract the feature name and importance values.\n\n# `variable_importances` is a list of <feature, importance> tuples.\nfeature_names = [vi[0].name for vi in variable_importances]\nfeature_importances = [vi[1] for vi in variable_importances]\n# The feature are ordered in decreasing importance value.\nfeature_ranks = range(len(feature_names))\n\nbar = plt.barh(feature_ranks, feature_importances, label=[str(x) for x in feature_ranks])\nplt.yticks(feature_ranks, feature_names)\nplt.gca().invert_yaxis()\n\n# TODO: Replace with \"plt.bar_label()\" when available.\n# Label each bar with values\nfor importance, patch in zip(feature_importances, bar.patches):\n  plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{importance:.4f}\", va=\"top\")\n\nplt.xlabel(variable_importance_metric)\nplt.title(\"NUM AS ROOT of the class 1 vs the others\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:18:10.614196Z","iopub.execute_input":"2024-08-05T13:18:10.614572Z","iopub.status.idle":"2024-08-05T13:18:11.167525Z","shell.execute_reply.started":"2024-08-05T13:18:10.614542Z","shell.execute_reply":"2024-08-05T13:18:11.166322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest predict","metadata":{}},{"cell_type":"code","source":"test_file_path = \"../input/house-prices-advanced-regression-techniques/test.csv\"\ntest_data = pd.read_csv(test_file_path)\nids = test_data.pop('Id')\n\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n    test_data,\n    task = tfdf.keras.Task.REGRESSION)\n\npreds = rf.predict(test_ds)\noutput = pd.DataFrame({'Id': ids,\n                       'SalePrice': preds.squeeze()})\n\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:18:11.168947Z","iopub.execute_input":"2024-08-05T13:18:11.169302Z","iopub.status.idle":"2024-08-05T13:18:12.172883Z","shell.execute_reply.started":"2024-08-05T13:18:11.169273Z","shell.execute_reply":"2024-08-05T13:18:12.171472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')\nsample_submission_df['SalePrice'] = rf.predict(test_ds)\nsample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\nsample_submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:18:12.174222Z","iopub.execute_input":"2024-08-05T13:18:12.174573Z","iopub.status.idle":"2024-08-05T13:18:12.534756Z","shell.execute_reply.started":"2024-08-05T13:18:12.174542Z","shell.execute_reply":"2024-08-05T13:18:12.533421Z"},"trusted":true},"execution_count":null,"outputs":[]}]}